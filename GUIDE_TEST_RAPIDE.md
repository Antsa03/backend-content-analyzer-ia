# ğŸ¯ Guide de Test Rapide

## âœ… Ã‰tape 1 : VÃ©rifier les installations

```bash
# VÃ©rifier que les packages sont installÃ©s
pip list | findstr "sentencepiece\|sacremoses\|protobuf"
```

Vous devriez voir :

```
protobuf          x.x.x
sacremoses        x.x.x
sentencepiece     x.x.x
```

## âœ… Ã‰tape 2 : Tester avec le script de test

```bash
python test_summary_quality.py
```

Ce script va :

1. ğŸ“Š GÃ©nÃ©rer un rÃ©sumÃ© TF-IDF (classique)
2. ğŸ§  GÃ©nÃ©rer un rÃ©sumÃ© avec BARThez (optimisÃ©)
3. ğŸ” Comparer les rÃ©sultats

## âœ… Ã‰tape 3 : Tester avec l'API

### DÃ©marrer le serveur

```bash
python main.py
```

### Tester un rÃ©sumÃ© neural (nouveau modÃ¨le)

```bash
# PowerShell
Invoke-RestMethod -Uri "http://localhost:8000/neural/summarize/text" `
  -Method POST `
  -ContentType "application/json" `
  -Body '{"text": "Votre texte ici...", "summary_length": "medium"}'
```

### Comparer TF-IDF vs Neural

```bash
# PowerShell
Invoke-RestMethod -Uri "http://localhost:8000/hybrid/summarize/text" `
  -Method POST `
  -ContentType "application/json" `
  -Body '{"text": "Votre texte ici...", "summary_length": "medium"}'
```

## ğŸ“Š Ce qui a changÃ©

### Avant (mBART gÃ©nÃ©raliste)

- âŒ Erreurs de tokenizer
- âŒ RÃ©sumÃ©s rÃ©pÃ©titifs
- âŒ QualitÃ© moyenne en franÃ§ais

### AprÃ¨s (BARThez optimisÃ©)

- âœ… Tokenizer stable
- âœ… Pas de rÃ©pÃ©titions
- âœ… Excellente qualitÃ© en franÃ§ais
- âœ… RÃ©sumÃ©s plus concis

## ğŸ›ï¸ ParamÃ¨tres Personnalisables

Dans `models/config.py`, vous pouvez ajuster :

```python
SUMMARIZER_CONFIG = {
    "model_name": "moussaKam/barthez-orangesum-abstract",  # ModÃ¨le FR optimisÃ©
    "generation_params": {
        "medium": {
            "num_beams": 6,              # â¬†ï¸ Augmenter pour plus de qualitÃ©
            "temperature": 0.9,          # â¬‡ï¸ Baisser pour plus de cohÃ©rence
            "repetition_penalty": 1.2,   # â¬†ï¸ Augmenter contre rÃ©pÃ©titions
        }
    }
}
```

## ğŸ”§ RÃ©solution de ProblÃ¨mes

### Le modÃ¨le ne se charge pas ?

```bash
# VÃ©rifier les dÃ©pendances
pip install --upgrade transformers torch sentencepiece sacremoses protobuf
```

### Toujours des erreurs de tokenizer ?

RedÃ©marrez l'application complÃ¨tement :

1. ArrÃªter tous les processus Python
2. Relancer `python main.py`

### QualitÃ© insuffisante ?

Essayez ces modÃ¨les alternatifs dans `neural_summarizer.py` :

```python
# Option 1 : T5 franÃ§ais (plus lourd mais trÃ¨s bon)
summarizer = model_manager.get_summarizer(
    model_name="plguillou/t5-base-fr-sum-cnndm"
)

# Option 2 : mT5 (plus lÃ©ger, multilingue)
summarizer = model_manager.get_summarizer(
    model_name="google/mt5-base"
)
```

## ğŸ“ˆ RÃ©sultats Attendus

**Texte d'entrÃ©e** : ~200 mots sur l'IA

**RÃ©sumÃ© Medium (40-150 mots)** :

- Temps : 2-5 secondes
- QualitÃ© : Excellente en franÃ§ais
- CohÃ©rence : TrÃ¨s bonne
- RÃ©pÃ©titions : Aucune

## ğŸ’¡ Prochaines Ã‰tapes

1. âœ… Tester avec `test_summary_quality.py`
2. âœ… Comparer avec vos propres textes
3. âœ… Ajuster les paramÃ¨tres si besoin
4. âœ… IntÃ©grer dans votre workflow

---

**Besoin d'aide ?** Consultez `AMELIORATIONS_RESUME.md` pour plus de dÃ©tails !
